# @package _global_
defaults:
  - /experiment/projects/bridging/experiment_image_feature_rec/_base
  - /dataset: coco
  - /experiment/projects/bridging/experiment_image_feature_rec/_preprocessing_coco_dino_feature_recon
  - /experiment/projects/bridging/dinosaur/_metrics_coco
  - _self_

# The following parameters assume training on 8 GPUs, leading to an effective batch size of 64.
trainer:
  devices: 8
  max_steps: 500000
  max_epochs:

dataset:
  num_workers: 4
  batch_size: 8

models:
  conditioning:
    _target_: routed.ocl.conditioning.RandomConditioning
    n_slots: 7
    object_dim: 256

    batch_size_path: input.batch_size
  feature_extractor:
    model_name: vit_base_patch16_224_dino
    pretrained: ${when_testing:false,true}
    freeze: false

  perceptual_grouping: {}
  object_decoder:
    _target_: routed.ocl.decoding.PatchDecoder
    object_dim: ${models.perceptual_grouping.object_dim}
    output_dim: ${experiment.input_feature_dim}
    num_patches: 196
    object_features_path: perceptual_grouping.objects
    target_path: feature_extractor.features
    image_path: input.image
    decoder:
      _target_: ocl.neural_networks.build_mlp
      _partial_: true
      features: [2048, 2048, 2048]

optimizers:
  opt0:
    # Add parameter groups for different learning rates.
    parameter_groups:
      - params: models.feature_extractor
        lr: 0.00004
      - params: [models.conditioning, models.perceptual_grouping, models.object_decoder]
        lr: 0.0004

experiment:
  input_feature_dim: 768
